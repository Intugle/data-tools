{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "757096f5",
   "metadata": {},
   "source": [
    "# Quickstart: Building a Semantic Layer with Data-Tools\n",
    "\n",
    "This notebook provides a quick introduction to the `data-tools` project. You'll learn how to use its key features to automatically build a semantic layer over your data.\n",
    "\n",
    "**What is a Semantic Layer?**\n",
    "\n",
    "A semantic layer is a business-friendly representation of your data. It hides the complexity of the underlying data sources and provides a unified view of your data using familiar business terms. This makes it easier for business users to understand and query the data without needing to be SQL experts.\n",
    "\n",
    "**Who is this for?**\n",
    "\n",
    "This tool is designed for both **data teams** and **business teams**. \n",
    "\n",
    "* **Data teams** can use it to automate data profiling, schema discovery, and documentation, significantly accelerating their workflow.\n",
    "* **Business teams** can use it to gain a better understanding of their data and to perform self-service analytics without needing to write complex SQL queries.\n",
    "\n",
    "**In this notebook, you will learn how to:**\n",
    "\n",
    "1. **Configure your LLM Provider:** Set up the Large Language Model that will power the automated features.\n",
    "2. **Profile your data:** Analyze your data sources to understand their structure, data types, and other characteristics.\n",
    "3. **Automatically predict links:** Use a Large Language Model (LLM) to automatically discover relationships (foreign keys) between tables.\n",
    "4. **Generate a semantic layer:** Create a `manifest.json` file that defines your semantic layer.\n",
    "5. **Generate SQL queries:** Use the semantic layer to generate SQL queries and retrieve data.\n",
    "\n",
    "**In this notebook, you will learn how to:**\n",
    "\n",
    "1. **Profile your data:** Analyze your data sources to understand their structure, data types, and other characteristics.\n",
    "2. **Automatically predict links:** Use a Large Language Model (LLM) to automatically discover relationships (foreign keys) between tables.\n",
    "3. **Generate a semantic layer:** Create a `manifest.json` file that defines your semantic layer.\n",
    "4. **Generate SQL queries:** Use the semantic layer to generate SQL queries and retrieve data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a1b244",
   "metadata": {},
   "source": [
    "## 1. LLM Configuration\n",
    "\n",
    "Before running the project, you need to configure a Large Language Model (LLM). This is used for tasks like generating business glossaries and predicting links between tables.\n",
    "\n",
    "You can configure the LLM by setting the following environment variables:\n",
    "\n",
    "* `LLM_PROVIDER`: The LLM provider and model to use (e.g., `openai:gpt-3.5-turbo`).\n",
    "* `OPENAI_API_KEY`: Your API key for the LLM provider.\n",
    "\n",
    "Here's an example of how to set these variables in your environment:\n",
    "\n",
    "```bash\n",
    "export LLM_PROVIDER=\"openai:gpt-3.5-turbo\"\n",
    "export OPENAI_API_KEY=\"your-openai-api-key\"\n",
    "```\n",
    "\n",
    "Alternatively, you can set them in the notebook like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36454d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LLM_PROVIDER\"] = \"openai:gpt-3.5-turbo\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\" # Replace with your actual key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dad9d8",
   "metadata": {},
   "source": [
    "## 2. Data Profiling\n",
    "\n",
    "The first step in building a semantic layer is to profile your data. This involves analyzing your data sources to understand their structure, data types, and other characteristics. The `data-tools` project provides a pipeline for this purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0e28d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raphael/intugle/data-tools/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/raphael/intugle/data-tools/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"schema\" in \"Source\" shadows an attribute in parent \"BaseResource\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from data_tools import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e8971bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>patient</th>\n",
       "      <th>encounter</th>\n",
       "      <th>code</th>\n",
       "      <th>system</th>\n",
       "      <th>description</th>\n",
       "      <th>type</th>\n",
       "      <th>category</th>\n",
       "      <th>reaction1</th>\n",
       "      <th>description1</th>\n",
       "      <th>severity1</th>\n",
       "      <th>reaction2</th>\n",
       "      <th>description2</th>\n",
       "      <th>severity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85</td>\n",
       "      <td>01efcc52-15d6-51e9-faa2-bee069fcbe44</td>\n",
       "      <td>111088007</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Latex (substance)</td>\n",
       "      <td>allergy</td>\n",
       "      <td>environment</td>\n",
       "      <td>247472004.0</td>\n",
       "      <td>Wheal (finding)</td>\n",
       "      <td>MILD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85</td>\n",
       "      <td>01efcc52-15d6-51e9-faa2-bee069fcbe44</td>\n",
       "      <td>84489001</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Mold (organism)</td>\n",
       "      <td>allergy</td>\n",
       "      <td>environment</td>\n",
       "      <td>76067001.0</td>\n",
       "      <td>Sneezing</td>\n",
       "      <td>MILD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85</td>\n",
       "      <td>01efcc52-15d6-51e9-faa2-bee069fcbe44</td>\n",
       "      <td>260147004</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>House dust mite (organism)</td>\n",
       "      <td>allergy</td>\n",
       "      <td>environment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85</td>\n",
       "      <td>01efcc52-15d6-51e9-faa2-bee069fcbe44</td>\n",
       "      <td>264287008</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Animal dander (substance)</td>\n",
       "      <td>allergy</td>\n",
       "      <td>environment</td>\n",
       "      <td>878820003.0</td>\n",
       "      <td>Rhinoconjunctivitis (disorder)</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>271807003.0</td>\n",
       "      <td>Eruption of skin (disorder)</td>\n",
       "      <td>MILD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85</td>\n",
       "      <td>01efcc52-15d6-51e9-faa2-bee069fcbe44</td>\n",
       "      <td>256277009</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Grass pollen (substance)</td>\n",
       "      <td>allergy</td>\n",
       "      <td>environment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start  stop                               patient  \\\n",
       "0  2020-02-17   NaN  b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85   \n",
       "1  2020-02-17   NaN  b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85   \n",
       "2  2020-02-17   NaN  b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85   \n",
       "3  2020-02-17   NaN  b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85   \n",
       "4  2020-02-17   NaN  b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85   \n",
       "\n",
       "                              encounter       code   system  \\\n",
       "0  01efcc52-15d6-51e9-faa2-bee069fcbe44  111088007  Unknown   \n",
       "1  01efcc52-15d6-51e9-faa2-bee069fcbe44   84489001  Unknown   \n",
       "2  01efcc52-15d6-51e9-faa2-bee069fcbe44  260147004  Unknown   \n",
       "3  01efcc52-15d6-51e9-faa2-bee069fcbe44  264287008  Unknown   \n",
       "4  01efcc52-15d6-51e9-faa2-bee069fcbe44  256277009  Unknown   \n",
       "\n",
       "                  description     type     category    reaction1  \\\n",
       "0           Latex (substance)  allergy  environment  247472004.0   \n",
       "1             Mold (organism)  allergy  environment   76067001.0   \n",
       "2  House dust mite (organism)  allergy  environment          NaN   \n",
       "3   Animal dander (substance)  allergy  environment  878820003.0   \n",
       "4    Grass pollen (substance)  allergy  environment          NaN   \n",
       "\n",
       "                     description1 severity1    reaction2  \\\n",
       "0                 Wheal (finding)      MILD          NaN   \n",
       "1                        Sneezing      MILD          NaN   \n",
       "2                             NaN       NaN          NaN   \n",
       "3  Rhinoconjunctivitis (disorder)  MODERATE  271807003.0   \n",
       "4                             NaN       NaN          NaN   \n",
       "\n",
       "                  description2 severity2  \n",
       "0                          NaN       NaN  \n",
       "1                          NaN       NaN  \n",
       "2                          NaN       NaN  \n",
       "3  Eruption of skin (disorder)      MILD  \n",
       "4                          NaN       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sample data\n",
    "allergies_df = pd.read_csv('https://raw.githubusercontent.com/Intugle/data-tools/refs/heads/main/sample_data/healthcare/allergies.csv')\n",
    "allergies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d3e8299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raphael/intugle/data-tools/.venv/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/raphael/intugle/data-tools/.venv/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "[!] Empty column encountered for allergies ==> stop ...\n",
      "  0%|          | 0/15 [00:00<?, ?it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      " 13%|█▎        | 2/15 [00:00<00:02,  6.21it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      " 20%|██        | 3/15 [00:00<00:02,  4.79it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      " 27%|██▋       | 4/15 [00:00<00:02,  4.30it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      " 33%|███▎      | 5/15 [00:01<00:02,  4.19it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      " 40%|████      | 6/15 [00:01<00:02,  3.76it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      " 47%|████▋     | 7/15 [00:01<00:02,  3.74it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      " 53%|█████▎    | 8/15 [00:01<00:01,  3.66it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      " 60%|██████    | 9/15 [00:02<00:01,  3.73it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      " 67%|██████▋   | 10/15 [00:02<00:01,  3.67it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      " 73%|███████▎  | 11/15 [00:02<00:01,  3.68it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      " 80%|████████  | 12/15 [00:03<00:00,  3.74it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      " 87%|████████▋ | 13/15 [00:03<00:00,  3.78it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      " 93%|█████████▎| 14/15 [00:03<00:00,  3.72it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.73it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Error while parsing: list index out of range\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.61it/s]\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "  0%|          | 0/15 [00:00<?, ?it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      " 13%|█▎        | 2/15 [00:00<00:03,  3.97it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      " 20%|██        | 3/15 [00:01<00:04,  2.72it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      " 27%|██▋       | 4/15 [00:01<00:04,  2.42it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      " 33%|███▎      | 5/15 [00:02<00:04,  2.20it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      " 40%|████      | 6/15 [00:02<00:04,  2.13it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      " 47%|████▋     | 7/15 [00:03<00:03,  2.02it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      " 53%|█████▎    | 8/15 [00:03<00:04,  1.64it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      " 60%|██████    | 9/15 [00:04<00:03,  1.70it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      " 67%|██████▋   | 10/15 [00:05<00:02,  1.70it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      " 73%|███████▎  | 11/15 [00:05<00:02,  1.77it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      " 80%|████████  | 12/15 [00:06<00:01,  1.82it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      " 87%|████████▋ | 13/15 [00:06<00:01,  1.74it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      " 93%|█████████▎| 14/15 [00:07<00:00,  1.82it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "100%|██████████| 15/15 [00:07<00:00,  1.75it/s][!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "[!] Error while llm invoke: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your-ope*******-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "[!] Langchain parser failed to parse ==>  ... trying manual_parsing parsing\n",
      "100%|██████████| 15/15 [00:08<00:00,  1.79it/s]\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ColumnGlossary\nbusiness_tags\n  Input should be a valid list [type=list_type, input_value='', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create a DataSet object and run the profiling pipeline\u001b[39;00m\n\u001b[32m      2\u001b[39m dataset_allergies = DataSet(allergies_df, \u001b[33m\"\u001b[39m\u001b[33mallergies\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdataset_allergies\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHealthcare\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intugle/data-tools/src/data_tools/analysis/models.py:166\u001b[39m, in \u001b[36mDataSet.run\u001b[39m\u001b[34m(self, domain)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, domain: \u001b[38;5;28mstr\u001b[39m) -> Self:\n\u001b[32m    161\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run all stages \"\"\"\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43midentify_datatypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43midentify_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_glossary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intugle/data-tools/src/data_tools/analysis/models.py:148\u001b[39m, in \u001b[36mDataSet.generate_glossary\u001b[39m\u001b[34m(self, domain)\u001b[39m\n\u001b[32m    145\u001b[39m column_profiles: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, ColumnProfile] = \u001b[38;5;28mself\u001b[39m.results[\u001b[33m\"\u001b[39m\u001b[33mcolumn_profiles\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    146\u001b[39m column_profiles_df = pd.DataFrame([col.model_dump() \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m column_profiles.values()])\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m glossary_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataframe_wrapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_business_glossary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_profiles_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdomain\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m glossary_output.columns:\n\u001b[32m    153\u001b[39m     column_profiles[column.column_name].business_glossary = column.business_glossary\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intugle/data-tools/src/data_tools/dataframes/dataframe.py:136\u001b[39m, in \u001b[36mDataFrame.generate_business_glossary\u001b[39m\u001b[34m(self, table_name, column_stats, domain)\u001b[39m\n\u001b[32m    133\u001b[39m columns_glossary = []\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m glossary_df.iterrows():\n\u001b[32m    135\u001b[39m     columns_glossary.append(\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m         \u001b[43mColumnGlossary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumn_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbusiness_glossary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbusiness_glossary\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbusiness_tags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbusiness_tags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     )\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BusinessGlossaryOutput(table_name=table_name, table_glossary=table_glossary, columns=columns_glossary)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intugle/data-tools/.venv/lib/python3.12/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for ColumnGlossary\nbusiness_tags\n  Input should be a valid list [type=list_type, input_value='', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type"
     ]
    }
   ],
   "source": [
    "# Create a DataSet object and run the profiling pipeline\n",
    "dataset_allergies = DataSet(allergies_df, \"allergies\")\n",
    "dataset_allergies.run(domain=\"Healthcare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ea58f",
   "metadata": {},
   "source": [
    "The `run()` method performs a series of analysis steps, including:\n",
    "\n",
    "* **Profiling:** Calculates statistics for each column, such as distinct count, uniqueness, and completeness.\n",
    "* **Datatype Identification:** Identifies the data type of each column (e.g., integer, string, datetime).\n",
    "* **Key Identification:** Identifies potential primary keys.\n",
    "* **Glossary Generation:** Generates a business glossary for each column using an LLM.\n",
    "\n",
    "> The `domain` parameter helps the LLM generate a more contextual business glossary. It specifies the industry domain that the dataset belongs to (e.g., \"Healthcare\", \"Finance\", \"E-commerce\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb562acd",
   "metadata": {},
   "source": [
    "## 3. Automated Link Prediction\n",
    "\n",
    "Now that we've profiled our data, let's discover the relationships between tables. The `data-tools` project uses a LLM to predict links (foreign keys) between tables.\n",
    "\n",
    "First, we'll load a few more tables from the sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa894eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = [\"patients\", \"claims\", \"careplans\", \"claims_transactions\", \"medications\"]\n",
    "datasets = [dataset_allergies]\n",
    "\n",
    "\n",
    "def generate_table_url(table_name: str) -> str:\n",
    "    \"\"\"Append the base URL to the table name.\"\"\"\n",
    "    return f\"https://raw.githubusercontent.com/Intugle/data-tools/refs/heads/main/sample_data/healthcare/{table_name}.csv\"\n",
    "\n",
    "\n",
    "for table_name in table_names:\n",
    "    table_url = generate_table_url(table_name)\n",
    "    df = pd.read_csv(table_url)\n",
    "    dataset = DataSet(df, table_name)\n",
    "    dataset.run(domain=\"Healthcare\")\n",
    "    datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e083a8d8",
   "metadata": {},
   "source": [
    "Now, let's run the link prediction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4cd56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_tools import LinkPredictor\n",
    "\n",
    "# Initialize the predictor\n",
    "predictor = LinkPredictor(datasets)\n",
    "\n",
    "# Run the prediction\n",
    "results = predictor.predict()\n",
    "results.links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18dc421",
   "metadata": {},
   "source": [
    "The `results` object contains the predicted links between the tables. You can also visualize the relationships as a graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59704ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.show_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fd4917",
   "metadata": {},
   "source": [
    "## 4. The Semantic Layer (Manifest)\n",
    "\n",
    "The profiling and link prediction results are used to generate a `manifest.json` file. This file defines the semantic layer, including the models (tables) and their relationships.\n",
    "\n",
    "Let's save the datasets and the predicted links to YAML files. By default, these files are saved in a `sources` directory in the current working directory. You can configure this path by setting the `PROJECT_BASE` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0daf854",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in datasets:\n",
    "    ds.save_yaml()\n",
    "\n",
    "results.save_yaml(\"relationships.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf08923",
   "metadata": {},
   "source": [
    "Now, we can load the YAML files and create a manifest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d086f45",
   "metadata": {},
   "source": [
    "## 5. SQL Generation\n",
    "\n",
    "Once you have a semantic layer, you can use the `SqlGenerator` to generate SQL queries. This allows you to query the data using business-friendly terms, without having to write complex SQL.\n",
    "\n",
    "Let's create an ETL model to define the query we want to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2570af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "etl = {\n",
    "    \"name\": \"test_etl\",\n",
    "    \"fields\": [\n",
    "        {\"id\": \"patients.first\", \"name\": \"first_name\"},\n",
    "        {\"id\": \"patients.last\", \"name\": \"last_name\"},\n",
    "        {\"id\": \"allergies.start\", \"name\": \"start_date\"},\n",
    "        {\"id\": \"encounters.total_claim_cost\", \"name\": \"claim_cost\", \"category\": \"measure\", \"measure_func\": \"sum\"},\n",
    "    ],\n",
    "    \"filter\": {\n",
    "        \"selections\": [{\"id\": \"claims.departmentid\", \"values\": [\"3\", \"20\"]}],\n",
    "        \"sort_by\": [{\"id\": \"encounters.start\", \"direction\": \"desc\"}],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ff6be",
   "metadata": {},
   "source": [
    "Now, let's use the `SqlGenerator` to generate the SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0432e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_tools.sql_generator import SqlGenerator\n",
    "\n",
    "# Create a SqlGenerator\n",
    "sql_generator = SqlGenerator()\n",
    "\n",
    "# Generate the query\n",
    "sql_query = sql_generator.generate_query(etl)\n",
    "\n",
    "# Print the query\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d33de",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has provided a brief overview of the `data-tools` project. You've learned how to:\n",
    "\n",
    "* Configure your LLM provider.\n",
    "* Profile your data to understand its characteristics.\n",
    "* Use an LLM to automatically predict links between tables.\n",
    "* Generate a semantic layer (`manifest.json`).\n",
    "* Use the semantic layer to generate SQL queries.\n",
    "\n",
    "This is just a starting point. The `data-tools` project has many other features to explore. We encourage you to try it with your own data and see how it can help you build a powerful semantic layer.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
