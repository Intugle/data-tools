"use strict";(self.webpackChunkdocsite=self.webpackChunkdocsite||[]).push([[53],{5575:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"core-concepts/dataset","title":"DataSet","description":"The DataSet class is the heart of the analysis pipeline. It acts as a powerful, in-memory container for a single data source, holding not just the raw data but also all the rich metadata that is generated about it during the KnowledgeBuilder\'s workflow.","source":"@site/docs/core-concepts/dataset.md","sourceDirName":"core-concepts","slug":"/core-concepts/dataset","permalink":"/data-tools/docs/core-concepts/dataset","draft":false,"unlisted":false,"editUrl":"https://github.com/Intugle/data-tools/tree/main/docsite/docs/core-concepts/dataset.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"DataSet"},"sidebar":"docsSidebar","previous":{"title":"The Knowledge Builder","permalink":"/data-tools/docs/core-concepts/knowledge-builder"},"next":{"title":"Link Prediction","permalink":"/data-tools/docs/core-concepts/link-prediction"}}');var s=n(4848),i=n(8453);const r={sidebar_position:3,title:"DataSet"},l="DataSet",o={},c=[{value:"Overview",id:"overview",level:2},{value:"Key Features",id:"key-features",level:2},{value:"Data Abstraction",id:"data-abstraction",level:3},{value:"Centralized Metadata",id:"centralized-metadata",level:3},{value:"Metadata Structure",id:"metadata-structure",level:4},{value:"Accessing Metadata",id:"accessing-metadata",level:4},{value:"Automatic Caching",id:"automatic-caching",level:3},{value:"Analysis Stage Functions",id:"analysis-stage-functions",level:3},{value:"Other Useful Methods and Properties",id:"other-useful-methods-and-properties",level:3},{value:"<code>save_yaml()</code>",id:"save_yaml",level:4},{value:"<code>reload_from_yaml()</code>",id:"reload_from_yaml",level:4},{value:"<code>profiling_df</code>",id:"profiling_df",level:4}];function d(e){const t={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"dataset",children:"DataSet"})}),"\n",(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(t.code,{children:"DataSet"})," class is the heart of the analysis pipeline. It acts as a powerful, in-memory container for a single data source, holding not just the raw data but also all the rich metadata that is generated about it during the ",(0,s.jsx)(t.code,{children:"KnowledgeBuilder"}),"'s workflow."]}),"\n",(0,s.jsx)(t.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsxs)(t.p,{children:["Think of a ",(0,s.jsx)(t.code,{children:"DataSet"}),' as a "unit of work" that gets progressively enriched as it moves through the analysis stages. Its key responsibilities are:']}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Data Abstraction"}),": It provides a consistent way to interact with data, regardless of its source."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Metadata Storage"}),": It serves as the central object for storing all analysis results."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Intelligent Caching"}),": It automatically persists and loads its own state, making the entire process efficient and resilient."]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"key-features",children:"Key Features"}),"\n",(0,s.jsx)(t.h3,{id:"data-abstraction",children:"Data Abstraction"}),"\n",(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(t.code,{children:"DataSet"})," uses a system of ",(0,s.jsx)(t.strong,{children:"Adapters"})," under the hood to connect to different data backends. When you initialize a ",(0,s.jsx)(t.code,{children:"DataSet"})," with a file-based source, it uses the appropriate adapter (e.g., ",(0,s.jsx)(t.code,{children:"DuckdbAdapter"})," for CSVs, Parquet, etc.) to handle the specific implementation details for profiling and querying the data. This makes the system easily extensible to support new data sources in the future."]}),"\n",(0,s.jsx)(t.h3,{id:"centralized-metadata",children:"Centralized Metadata"}),"\n",(0,s.jsxs)(t.p,{children:["All analysis results for a data source are stored within the ",(0,s.jsx)(t.code,{children:"dataset.source_table_model"})," attribute. This attribute is a structured Pydantic model that makes accessing metadata predictable and easy."]}),"\n",(0,s.jsx)(t.h4,{id:"metadata-structure",children:"Metadata Structure"}),"\n",(0,s.jsx)(t.p,{children:"The metadata is organized using the following Pydantic models:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"SourceTables"}),": The root object, containing table-level information.","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.code,{children:"name: str"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.code,{children:"description: str"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.code,{children:"key: Optional[str]"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.code,{children:"columns: List[Column]"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.code,{children:"profiling_metrics: Optional[ModelProfilingMetrics]"})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"Column"}),": Contains metadata for a single column.","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.code,{children:"name: str"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.code,{children:"description: Optional[str]"})}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"type: Optional[str]"})," (e.g., 'integer', 'date')"]}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.code,{children:'category: Literal["dimension", "measure"]'})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.code,{children:"tags: Optional[List[str]]"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.code,{children:"profiling_metrics: Optional[ColumnProfilingMetrics]"})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"ColumnProfilingMetrics"}),": Detailed statistics for a column.","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.code,{children:"count: Optional[int]"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.code,{children:"null_count: Optional[int]"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.code,{children:"distinct_count: Optional[int]"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.h4,{id:"accessing-metadata",children:"Accessing Metadata"}),"\n",(0,s.jsxs)(t.p,{children:["You can access this rich metadata directly from the ",(0,s.jsx)(t.code,{children:"DataSet"})," object."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Assuming \'kb\' is a built KnowledgeBuilder instance\ncustomers_dataset = kb.datasets[\'customers\']\n\n# Access table-level metadata\nprint(f"Table Name: {customers_dataset.source_table_model.name}")\nprint(f"Table Description: {customers_dataset.source_table_model.description}")\nprint(f"Primary Key: {customers_dataset.source_table_model.key}")\n\n# Access column-level metadata for the first column\nfirst_column = customers_dataset.source_table_model.columns[0]\nprint(f"Column Name: {first_column.name}")\nprint(f"Column Description: {first_column.description}")\nprint(f"Column Type: {first_column.type}")\n\n# Access profiling metrics for that column\nmetrics = first_column.profiling_metrics\nif metrics:\n    print(f"Distinct Count: {metrics.distinct_count}")\n'})}),"\n",(0,s.jsx)(t.h3,{id:"automatic-caching",children:"Automatic Caching"}),"\n",(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(t.code,{children:"DataSet"})," object is designed to be efficient by avoiding redundant work. When you initialize a ",(0,s.jsx)(t.code,{children:"DataSet"}),", it automatically checks for a corresponding ",(0,s.jsx)(t.code,{children:".yml"})," file. If it finds one, it validates that the source data file hasn't changed since the last run. If the data is fresh, it loads the saved metadata, saving significant processing time."]}),"\n",(0,s.jsx)(t.h3,{id:"analysis-stage-functions",children:"Analysis Stage Functions"}),"\n",(0,s.jsxs)(t.p,{children:["You can run the analysis pipeline step-by-step for more granular control. Each of these methods includes a ",(0,s.jsx)(t.code,{children:"save=True"})," option to persist the results of that specific stage."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from intugle import DataSet\n\n# Initialize the dataset\ndata_source = {"path": "path/to/my_data.csv", "type": "csv"}\ndataset = DataSet(data_source, name="my_data")\n\n# Run each stage individually and save progress\nprint("Step 1: Profiling...")\ndataset.profile(save=True)\n\nprint("Step 2: Identifying Datatypes...")\ndataset.identify_datatypes(save=True)\n\nprint("Step 3: Identifying Keys...")\ndataset.identify_keys(save=True)\n\nprint("Step 4: Generating Glossary...")\ndataset.generate_glossary(domain="my_domain", save=True)\n'})}),"\n",(0,s.jsx)(t.h3,{id:"other-useful-methods-and-properties",children:"Other Useful Methods and Properties"}),"\n",(0,s.jsx)(t.h4,{id:"save_yaml",children:(0,s.jsx)(t.code,{children:"save_yaml()"})}),"\n",(0,s.jsxs)(t.p,{children:["Manually trigger a save of the dataset's current state to its ",(0,s.jsx)(t.code,{children:".yml"})," file."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:"dataset.save_yaml()\n"})}),"\n",(0,s.jsx)(t.h4,{id:"reload_from_yaml",children:(0,s.jsx)(t.code,{children:"reload_from_yaml()"})}),"\n",(0,s.jsx)(t.p,{children:"Force a reload from the YAML file, bypassing the staleness check. This can be useful if you manually edit the YAML and want to load your changes."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'file_path = "path/to/my_data.yml"\ndataset.reload_from_yaml(file_path)\n'})}),"\n",(0,s.jsx)(t.h4,{id:"profiling_df",children:(0,s.jsx)(t.code,{children:"profiling_df"})}),"\n",(0,s.jsx)(t.p,{children:"Access a Pandas DataFrame containing the complete profiling results for all columns in the dataset. This is very useful for exploration and validation in a notebook environment."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:"# Get a comprehensive DataFrame of all column profiles\nprofiles = dataset.profiling_df\n\n# Display the first 5 rows\nprint(profiles.head())\n"})})]})}function h(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>l});var a=n(6540);const s={},i=a.createContext(s);function r(e){const t=a.useContext(i);return a.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),a.createElement(i.Provider,{value:t},e.children)}}}]);