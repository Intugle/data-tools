{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart: Conceptual Search\n",
    "\n",
    "This notebook provides a hands-on walkthrough of the **Conceptual Search** feature in the `intugle` library. You'll learn how to use natural language to generate, refine, and build a unified data product from a semantic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's install the `intugle` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install intugle -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables\n",
    "\n",
    "Conceptual Search relies on Large Language Models (LLMs) for its AI capabilities. You'll need to configure an LLM provider and API key. For this example, we'll use OpenAI.\n",
    "\n",
    "## 1. LLM Configuration\n",
    "\n",
    "Before running the project, you need to configure a Large Language Model (LLM). This is used for tasks like generating business glossaries and predicting links between tables. You will also need to set up Qdrant and provide an OpenAI API key. For detailed setup instructions, please refer to the [README.md](README.md) file.\n",
    "\n",
    "You can configure the necessary services by setting the following environment variables:\n",
    "\n",
    "*   `LLM_PROVIDER`: The LLM provider and model to use (e.g., `openai:gpt-3.5-turbo`). The format follows langchain's format for initializing chat models. Checkout how to specify your model [here](https://python.langchain.com/docs/integrations/chat/)\n",
    "*   `API_KEY`: Your API key for the LLM provider. The exact name of the variable may vary from provider to provider (e.g., `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`).\n",
    "*   `QDRANT_URL`: The URL of your Qdrant instance (e.g., `http://localhost:6333`).\n",
    "*   `QDRANT_API_KEY`: Your API key for the Qdrant instance, if authorization is enabled.\n",
    "*   `EMBEDDING_MODEL_NAME`: The embedding model to use. The format follows LangChain's conventions for initializing embedding models (e.g., `openai:ada`, `azure_openai:ada`).\n",
    "*   `OPENAI_API_KEY`: Your OpenAI API key, required if you are using an OpenAI embedding model.\n",
    "*   `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`, `OPENAI_API_VERSION`: Your Azure OpenAI credentials, required if you are using an Azure OpenAI embedding model.\n",
    "\n",
    "For the best results, we also recommend setting a **Tavily API key**, which allows the planning agent to perform web searches for better contextual understanding.\n",
    "\n",
    "Here's an example of how to set these variables in your environment:\n",
    "\n",
    "```bash\n",
    "export LLM_PROVIDER=\"openai:gpt-3.5-turbo\"\n",
    "export OPENAI_API_KEY=\"your-openai-api-key\"\n",
    "```\n",
    "Alternatively, you can set them in the notebook like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LLM_PROVIDER\"] = \"openai:gpt-3.5-turbo\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"  # Replace with your actual key\n",
    "\n",
    "# Qdrant Configuration\n",
    "os.environ[\"QDRANT_URL\"] = \"http://localhost:6333\"\n",
    "os.environ[\"QDRANT_API_KEY\"] = \"\"  # if authorization is used\n",
    "os.environ[\"EMBEDDING_MODEL_NAME\"] = \"openai:ada\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
    "\n",
    "# For Azure OpenAI models\n",
    "os.environ[\"EMBEDDING_MODEL_NAME\"] = \"azure_openai:ada\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"your-azure-openai-api-key\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"your-azure-openai-endpoint\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"your-openai-api-version\"\n",
    "\n",
    "# TAVILY\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"YOUR_TAVILY_API_KEY\" # Optional, but recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Sample Data\n",
    "\n",
    "We'll use the healthcare dataset for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "raw_datasets='healthcare'\n",
    "api_url = f\"https://api.github.com/repos/Intugle/data-tools/contents/sample_data/{raw_datasets}\"\n",
    "local_dir = f\"sample_data/{raw_datasets}\"\n",
    "os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "r = requests.get(api_url)\n",
    "r.raise_for_status()\n",
    "\n",
    "for item in r.json():\n",
    "    if item[\"name\"].endswith(\".csv\"):\n",
    "        print(f\"Downloading {item['name']}...\")\n",
    "        file_data = requests.get(item[\"download_url\"])\n",
    "        with open(os.path.join(local_dir, item[\"name\"]), \"wb\") as f:\n",
    "            f.write(file_data.content)\n",
    "\n",
    "print(\"All CSV files downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Semantic Model\n",
    "\n",
    "Conceptual Search operates on top of a semantic layer. Before we can use it, we need to build this layer using the `SemanticModel` class. This process involves profiling the data, predicting links between tables, and generating a business glossary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_config(table_name: str) -> str:\n",
    "    \"\"\"Append the base URL to the table name.\"\"\"\n",
    "    return {\n",
    "        \"path\": f\"./sample_data/healthcare/{table_name}.csv\",\n",
    "        \"type\": \"csv\",\n",
    "    }\n",
    "\n",
    "\n",
    "table_names = [\n",
    "    \"allergies\",\n",
    "    \"careplans\",\n",
    "    \"claims\",\n",
    "    \"claims_transactions\",\n",
    "    \"conditions\",\n",
    "    \"devices\",\n",
    "    \"encounters\",\n",
    "    \"imaging_studies\",\n",
    "    \"immunizations\",\n",
    "    \"medications\",\n",
    "    \"observations\",\n",
    "    \"organizations\",\n",
    "    \"patients\",\n",
    "    \"payers\",\n",
    "    \"payer_transitions\",\n",
    "    \"procedures\",\n",
    "    \"providers\",\n",
    "    \"supplies\",\n",
    "]\n",
    "\n",
    "datasets = {table: generate_config(table) for table in table_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate a Data Product Plan\n",
    "\n",
    "Now that the semantic layer is built, we can use the `DataProduct` class to generate a plan from a natural language query. The `plan()` method kicks off the first stage of Conceptual Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intugle import DataProduct\n",
    "\n",
    "dp = DataProduct()\n",
    "\n",
    "# Generate a plan from a natural language query\n",
    "query = \"patient 360 view\"\n",
    "data_product_plan = await dp.plan(query=query)\n",
    "data_product_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modify the Plan\n",
    "\n",
    "The generated plan is a starting point. You can programmatically modify it to refine the final output. Let's rename an attribute and disable another one that we don't need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume the plan included 'Patient Last Name' and we want to rename it\n",
    "data_product_plan.rename_attribute('Patient Last Name', 'Family Name')\n",
    "\n",
    "# Let's also assume it included 'Patient Birth Date' which we don't need\n",
    "data_product_plan.disable_attribute('Patient Birth Date')\n",
    "\n",
    "print(\"--- Modified Plan ---\")\n",
    "data_product_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the Data Product\n",
    "\n",
    "Once you're satisfied with the plan, you can proceed to the building stage. This will trigger the second AI agent to map the plan's attributes to physical columns and generate the final SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the data product from the modified plan\n",
    "data_product = await dp.build_from_plan(data_product_plan)\n",
    "\n",
    "# Access the results as a pandas DataFrame\n",
    "df = data_product.to_df()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also inspect the final, generated SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_product.sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You have successfully used Conceptual Search to:\n",
    "1.  Generate a data product plan from a natural language query.\n",
    "2.  Review and modify the AI-generated plan.\n",
    "3.  Build a unified data product without writing any SQL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
